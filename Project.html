<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">
    <title>Assistive Technology</title>
    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom styles for this template -->
    <link href="css/Style.css" rel="stylesheet">
	<!-- Google Analytics Tag -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		
		ga('create', 'UA-102917902-1', 'auto');
		ga('send', 'pageview');
	</script>
  </head>
  <body>
    <div class="container">
      <!-- The justified navigation menu is meant for single line per list item.
           Multiple lines will require custom code not provided by Bootstrap. -->
      <div class="masthead">
        <nav>
          <ul class="nav nav-justified">
            <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
            <li class="nav-item"><a class="nav-link" href="About.html">About Us</a></li>
            <li class="nav-item"><a class="nav-link active" href="Project.html">Projects</a></li>
            <li class="nav-item"><a class="nav-link" href="Publication.html">Publications</a></li>
          </ul>
        </nav>
      </div>
      <!-- Jumbotron -->
      <div class="jumbotron">
	  <hr>
		<h1>Otago Polytechnic Accessibility Software Hub</h1>
		<hr>
		<h4> Our Projects </h4>
		<br>
		<br>
        <p class="lead">Below are the accessibility software solutions we have developed over time. Each box points to a GitHub repository where you can download the software to use it, read a user guide and even contribute to the project if you have the technical skills.</p>
          
          <p>
          Please bear in mind that the following are software applications created by students who still do not have the level of expertise and skills of professional software developers. As a result, the software quality and documentation are at times sub optimal, which might affect the user experience. These software applications are intended for motor impaired users with very constrained financial situations who cannot afford a high quality, but expensive, accessibility software solution. If you can afford around $3000, you might be better off with proprietary accessibility software and the associated eye tracker hardware from a commercial company such as Tobii.
          </p>
          <p>
          <a href="http://www.tobiidynavox.com/windows-control/">Tobii Windows Control  </a>    
          </p>
          <p>
          <a href="https://www.tobiiati-webshop.com/products/pceye-mini?utm_source=tobiidynavox.com&utm_medium=Banner&utm_content=frontPagePromoBox&utm_campaign=genericPCEyeMini&_ga=1.51140585.1952117328.1482820918">Tobii Eye Tracking Hardware</a>    
          </p>
	  </div>
	  <!-- START THE FEATURETTES -->
      <hr class="featurette-divider">
      <div class="row featurette">
        <div class="col-lg-12 col-md-7">
          <h2 class="featurette-heading">Open Source Windows Gaze Control</h2>
          <p class="lead">This software allows you to fully control a Windows computer using only your eyes and a low-cost eye tracker. The gaze only interaction is achieved using a two-step process by which you select a desired task (left mouse click, right mouse click, scrolling, etc.) by gazing at a gaze reactive taskbar on the border of the computer screen. The software also allows the augmentation of the system via accessibility switches to speed up interaction.  <a href="https://github.com/OtagoPolytechnicAccessabilitySotwareHub/OpenSourceWindowsGazeControl">Download from Github here</a></p>
        <div class = "video-container">
		<iframe src="https://www.youtube.com/embed/uP3FdVz4O7Y" allowfullscreen></iframe>
		</div>
		</div>
        <div class="col-md-5">

        </div>
      </div>
        
      <hr class="featurette-divider">
	  	  <br><br><br>
        
      <div class="row featurette">
        <div class="col-lg-12 col-md-7">
          <h2 class="featurette-heading">OptiKey Lite</span></h2>
          <p class="lead">A minimalistic gaze aware on-screen keyboard branched from the <a href="https://github.com/OptiKey/OptiKey/wiki">OptiKey</a> project that allows users with speech disabilities to synthesize voice using only their eyes to type the messages they wish to communicate.  <a href="https://github.com/OtagoPolytechnicAccessabilitySotwareHub/OptiKeyLite">Download from Github here</a></p>
        <div class = "video-container">
		<iframe src="https://www.youtube.com/embed/J7b8Z6o49EE" allowfullscreen/>
        </iframe>
		</div>
		</div>
        <div class="col-md-5">
          
        </div>
      </div>
   
    <hr class="featurette-divider">


      <div class="row featurette">
        <div class="col-lg-12 col-md-7">
          <h2 class="featurette-heading">Icon Based Communicator</span></h2>
          <p class="lead">An iconic keyboard that allows users who cannot read or write to communicate via gaze aware semantic icons.  <a href="https://github.com/accessibilitysoftwarehub/iconBasedCommunicator/releases">Download from Github here</a></p>
        <div class = "video-container">
		<iframe src="https://www.youtube.com/embed/3EDoeLP_gEw"  allowfullscreen>
		</iframe>
		</div>
      </div>
   
    <hr class="featurette-divider">
	  	  
      
      
      
      <div class="row featurette">
        <div class="col-lg-12 col-md-7">
          <h2 class="featurette-heading">Face Switch</span></h2>
          <p class="lead">The FaceSwitch is an application that transforms predefined facial gestures to specific keyboard keystrokes. The program leverages the deformable face tracker <a href="https://www.beyond-reality-face.com/"> Beyond Reality Face Tracker</a> to create a multi-switch system driven by face gestures. The FaceSwitch is intended to help computer users with limited mobility from the neck down but who have a good level of control of facial muscles by allowing those users to use facial gestures as on-off switches to control accessibility software. The software is intended to be used in combination with gaze control but can be used in other contexts as well. <a href="https://github.com/OtagoPolytechnicAccessabilitySotwareHub/FaceSwitch">Download from Github here</a></p>
        <div class = "video-container">
		<iframe src="https://www.youtube.com/embed/DXKa6hj2uFg" allowfullscreen></iframe>
		</div>
		</div>
        <div class="col-md-5">
          
        </div>
      </div>      
        
      <hr class="featurette-divider">
	  <br>
	  <br>
	  <br>
	  <br>
      <div class="row featurette">
        <div class="col-lg-12 col-md-7 push-md-5">
          <h2 class="featurette-heading">Speech Input</span></h2>
          <p class="lead">This application allows you to input text at will in any user interface of a Windows computer using only your voice.  <a href="https://github.com/OtagoPolytechnicAccessabilitySotwareHub/SpeechInput">Download from Github here</a></p>
            <div class = "video-container">
		<div class = "video-container">
			<iframe src="https://www.youtube.com/embed/cHdFA1Obexk" allowfullscreen></iframe>
		</div>
        </div>
		</div>
        <div class="col-md-5 pull-md-7">
          
        </div>
      </div>
      <hr class="featurette-divider">
	  <br>
	  <br>
	  <br>
	  <br>
      <div class="row featurette">
        <div class="col-lg-12 col-md-7">
          <h2 class="featurette-heading">Sound Switch</span></h2>
          <p class="lead">This application allows you to create customized sound switches which you can use to control a computer. The software allows the user the opportunity to create several on/off switches which are reactive to sounds generated by the user at will (such as for instance tongue snaps) and to map the given sounds to specific control commands to operate a computer. The battery of switches at the disposal of the user provides several additional degrees of freedom to enhance assistive technologies such as gaze interaction for computer control.  <a href="https://github.com/OtagoPolytechnicAccessabilitySotwareHub/SoundSwitch">Download from Github here</a></p>
        <div class = "video-container">
		     <iframe src="https://www.youtube.com/embed/MB__dEc0aZU" allowfullscreen></iframe>
		</div>
		</div>
        <div class="col-md-5">

        </div>
      </div>
      <hr class="featurette-divider">
	  	  <br>
	  <br>
	  <br>

	  <br>
	  <br>
	  	<img class="logo" src="images/Poly.png" alt="Otago Polytechnic logo">   			  
	  <hr>
	  
      <!-- /END THE FEATURETTES -->
    </div> <!-- /container -->
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>